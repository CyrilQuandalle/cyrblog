---
layout: post
title: "Microsoft Cloud Summit Paris : Première journée"
date: 2017-01-24 21:45
author: sylvain martinez
comments: true
categories: [Non classé]
---
La première journée du Microsoft Cloud Summit Paris s’est ouverte avec la traditionnelle Key Note.

Après une rapide introduction, rappelant le caractère communautaire de cet évènement, axé autour de l’écosystème Azure (mais pas que),  Rohan Kumar, General Manager for Database Systems, nous a présenté les enjeux et l’évolution du Cloud, avec un focus sur la data, son stockage, son exploitation, et la rapidité à obtenir des résultats business pouvant impacter la stratégie des entreprises. L’intelligence artificielle se trouve au cœur de ces traitements,  et sa maitrise (ainsi que les couts associés) est un véritable enjeu pour l’avenir.

Cette introduction a été l’occasion de voir en action le traitement de 10.000.000.000.000 enregistrements dans un SQL Datawarhouse de taille conséquente. Une démo assez bluffante, mais que je vous déconseille d’essayer de reproduire avec votre souscription Azure.

Nous avons aussi pu voir comment le Cloud Azure, avec l’ensemble  des services fournies et notamment ses possibilités de scaling et de haute disponibilité se positionne comme un sérieux concurrent.

&nbsp;

<strong>Document DB</strong>

&nbsp;

La première session à laquelle j’ai assisté était une présentation de Azure Document DB, par Arnaud Comet, Program Manager.

Document DB est la base de données NoSql de la plateforme Azure. Son développement a commencé en 2010, et s’est achevé en 2014. La GA est arrivée en 2015. Elle fait maintenant partie du Ring 0 (ie Document DB sera disponible dans tout nouveau Data Center).

Document DB est à la fois une base Document (si si) mais également un Key-Value store. La roadmap prévoit également la possibilité de l'utiliser comme un Column store ou une graph Database !

Document DB est plutôt chère, c’est un fait. Mais cela s’explique par le SLA garanti : 99,99% et des temps de latence inférieure à 10ms. Cette performance nécessite un stockage adaptée (SSD)  et 3 replicas au sein du même Data Center. Une offre moins performante mais plus accessible financièrement devrait voir le jour.

La Géo-réplication est bien sur disponible, sur plusieurs régions, ainsi qu'un mécanisme de Fail Over garantissant une haute disponibilitée.

Nous avons pu voir comment en jouant sur

<ol>
    <li>Une bonne estimation de sa consommation :</li>
    <li>Une bonne gestion des Partitions Keys</li>
    <li>L'utilisation du scaling</li>
    <li><strong>Une bonne estimation de sa consommation </strong></li>
</ol>

On pouvait
